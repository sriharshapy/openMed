{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14fa5ea4-7cd0-4208-b776-bbd3de7d8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.backends import mps\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, confusion_matrix\n",
    "from imblearn.metrics import sensitivity_score, specificity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09707939-4f7c-4822-8ebc-e778d5785f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Get the best available device for training.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"CUDA device detected: {torch.cuda.get_device_name()}\")\n",
    "        return device\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"MPS device detected (Apple Silicon)\")\n",
    "        return device\n",
    "    else:\n",
    "        print(\"No GPU available, using CPU\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96492926-27b8-4858-8087-a0eacc327d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50FineTuned(nn.Module):\n",
    "    \"\"\"ResNet50 with ImageNet pretrained weights, fine-tuning only the last layer.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2, freeze_features=True):\n",
    "        super(ResNet50FineTuned, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet50\n",
    "        self.resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        \n",
    "        # Freeze all layers except the final classifier if freeze_features=True\n",
    "        if freeze_features:\n",
    "            for param in self.resnet50.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        # ResNet50 has 2048 features in the final layer\n",
    "        num_features = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        # Ensure the final layer is trainable\n",
    "        for param in self.resnet50.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        print(f\"ResNet50 loaded with ImageNet weights. Final layer: {num_features} -> {num_classes}\")\n",
    "        if freeze_features:\n",
    "            print(\"All layers frozen except final classifier layer\")\n",
    "        else:\n",
    "            print(\"All layers trainable\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "    \n",
    "    def get_trainable_params(self):\n",
    "        \"\"\"Return only trainable parameters.\"\"\"\n",
    "        return [param for param in self.parameters() if param.requires_grad]\n",
    "    \n",
    "    def get_num_trainable_params(self):\n",
    "        \"\"\"Return number of trainable parameters.\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c70872e6-b4f7-4f6e-9eac-22297cbf2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"Custom dataset for chest x-ray classification.\"\"\"\n",
    "    def __init__(self, root_dir, transform=None, max_samples_per_class=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with subdirectories for each class (NORMAL, PNEUMONIA)\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            max_samples_per_class (int, optional): Maximum number of samples per class to load.\n",
    "                                                  If None, loads all samples.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "        self.max_samples_per_class = max_samples_per_class\n",
    "        \n",
    "        # Get class directories\n",
    "        class_dirs = [d for d in os.listdir(root_dir) \n",
    "                     if os.path.isdir(os.path.join(root_dir, d))]\n",
    "        class_dirs.sort()  # Ensure consistent ordering\n",
    "        self.class_names = class_dirs\n",
    "        \n",
    "        print(f\"Found {len(class_dirs)} classes: {class_dirs}\")\n",
    "        if max_samples_per_class:\n",
    "            print(f\"Limiting to {max_samples_per_class} samples per class\")\n",
    "        \n",
    "        # Create mapping from class name to index\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(class_dirs)}\n",
    "        \n",
    "        # Collect all image paths and labels\n",
    "        for class_name in class_dirs:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            # Get all image files for this class\n",
    "            class_images = []\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    class_images.append(os.path.join(class_dir, img_name))\n",
    "            \n",
    "            # Limit samples per class if specified\n",
    "            if max_samples_per_class and len(class_images) > max_samples_per_class:\n",
    "                # Randomly sample max_samples_per_class images\n",
    "                import random\n",
    "                random.seed(42)  # For reproducibility\n",
    "                class_images = random.sample(class_images, max_samples_per_class)\n",
    "            \n",
    "            # Add to dataset\n",
    "            for img_path in class_images:\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(class_idx)\n",
    "        \n",
    "        print(f\"Total samples: {len(self.image_paths)}\")\n",
    "        for class_name, class_idx in self.class_to_idx.items():\n",
    "            count = sum(1 for label in self.labels if label == class_idx)\n",
    "            print(f\"  {class_name}: {count} samples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef1178ed-5634-41ef-b3c6-db95ddc16c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, epoch: int = -1, dataset: str = \"\", criterion=None, device=None):\n",
    "    \"\"\"Evaluate model performance on test set.\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=f\"Testing {dataset}\"):\n",
    "            images = images.to(device=device, dtype=torch.float32)\n",
    "            labels = labels.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            if criterion:\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "            \n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probabilities = np.array(all_probabilities)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    # For binary classification, calculate additional metrics\n",
    "    if all_probabilities.shape[1] == 2:\n",
    "        try:\n",
    "            auc = roc_auc_score(all_labels, all_probabilities[:, 1])\n",
    "        except ValueError:\n",
    "            auc = None\n",
    "            \n",
    "        sensitivity = sensitivity_score(all_labels, all_predictions, average='binary')\n",
    "        specificity = specificity_score(all_labels, all_predictions, average='binary')\n",
    "        ppv = precision_score(all_labels, all_predictions, average='binary')\n",
    "    else:\n",
    "        auc = None\n",
    "        sensitivity = sensitivity_score(all_labels, all_predictions, average='macro')\n",
    "        specificity = specificity_score(all_labels, all_predictions, average='macro')\n",
    "        ppv = precision_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    confusion_mat = confusion_matrix(all_labels, all_predictions)\n",
    "    test_loss = test_loss / len(test_loader) if criterion else 0\n",
    "    \n",
    "    return auc, sensitivity, specificity, accuracy, f1, ppv, confusion_mat, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e62a398-698d-4986-9188-514296064311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet50_model(\n",
    "        root_path: str,\n",
    "        freeze_features: bool = True,\n",
    "        normalize_mean: list = [0.485, 0.456, 0.406],\n",
    "        normalize_std: list = [0.229, 0.224, 0.225],\n",
    "        epochs: int = 10,\n",
    "        batch_size: int = 32,\n",
    "        lr: float = 1e-3,\n",
    "        seed: int = 42,\n",
    "        load_path: str = \"\",\n",
    "        save_checkpoint: bool = True,\n",
    "        save_interval: int = 5,\n",
    "        save_path: str = \"./checkpoints\",\n",
    "        use_mlflow: bool = True,\n",
    "        experiment_name: str = \"ResNet50_ChestXray_FineTuning\",\n",
    "        device=None,\n",
    "        amp: bool = False,\n",
    "        num_classes: int = 2,\n",
    "        max_samples_per_class: int = None\n",
    "):\n",
    "    \"\"\"Main training function for ResNet50 fine-tuning.\"\"\"\n",
    "    \n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Start MLflow run\n",
    "    if use_mlflow:\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        mlflow.start_run()\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model_type\", \"ResNet50_FineTuned\")\n",
    "        mlflow.log_param(\"freeze_features\", freeze_features)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"seed\", seed)\n",
    "        mlflow.log_param(\"device\", device.type)\n",
    "        mlflow.log_param(\"amp\", amp)\n",
    "        mlflow.log_param(\"num_classes\", num_classes)\n",
    "        mlflow.log_param(\"normalize_mean\", normalize_mean)\n",
    "        mlflow.log_param(\"normalize_std\", normalize_std)\n",
    "        mlflow.log_param(\"max_samples_per_class\", max_samples_per_class)\n",
    "    \n",
    "    # Create model\n",
    "    model = ResNet50FineTuned(num_classes=num_classes, freeze_features=freeze_features)\n",
    "    \n",
    "    # Log model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = model.get_num_trainable_params()\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Percentage of trainable parameters: {100 * trainable_params / total_params:.2f}%\")\n",
    "    \n",
    "    if use_mlflow:\n",
    "        mlflow.log_param(\"total_params\", total_params)\n",
    "        mlflow.log_param(\"trainable_params\", trainable_params)\n",
    "        mlflow.log_param(\"trainable_percentage\", 100 * trainable_params / total_params)\n",
    "    \n",
    "    # Create datasets with ImageNet normalization\n",
    "    normalize = transforms.Normalize(normalize_mean, normalize_std)\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomAffine(degrees=10, translate=(0.02, 0.02)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    \n",
    "    # Use chest x-ray dataset structure\n",
    "    train_dir = os.path.join(root_path, \"train\")\n",
    "    test_dir = os.path.join(root_path, \"test\")\n",
    "    \n",
    "    if not all(os.path.exists(path) for path in [train_dir, test_dir]):\n",
    "        raise FileNotFoundError(f\"Required data directories not found in {root_path}. \"\n",
    "                                f\"Ensure train/ and test/ directories exist.\")\n",
    "    \n",
    "    dataset_train = ChestXrayDataset(root_dir=train_dir, transform=train_transform, max_samples_per_class=max_samples_per_class)\n",
    "    dataset_test = ChestXrayDataset(root_dir=test_dir, transform=test_transform, max_samples_per_class=max_samples_per_class)\n",
    "    \n",
    "    train_loader = DataLoader(dataset_train, batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(dataset_test, batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Log dataset information\n",
    "    if use_mlflow:\n",
    "        mlflow.log_param(\"train_size\", len(dataset_train))\n",
    "        mlflow.log_param(\"test_size\", len(dataset_test))\n",
    "        mlflow.log_param(\"data_path\", root_path)\n",
    "    \n",
    "    # Training setup\n",
    "    info = f'''\n",
    "        Model: ResNet50 Fine-tuned (ImageNet pretrained)\n",
    "        Freeze features: {freeze_features}\n",
    "        Seed: {seed}, Batch size: {batch_size}, Epochs: {epochs}\n",
    "        Learning rate: {lr}, Data path: {root_path}\n",
    "        Training size: {len(dataset_train)}, Test size: {len(dataset_test)}\n",
    "        Device: {device.type}, Save checkpoints: {save_checkpoint}\n",
    "        Trainable params: {trainable_params:,} / {total_params:,} ({100 * trainable_params / total_params:.1f}%)\n",
    "    '''\n",
    "    print(info)\n",
    "    \n",
    "    if load_path and os.path.exists(load_path):\n",
    "        model.load_state_dict(torch.load(load_path, map_location=device))\n",
    "        print(f\"Loaded checkpoint from {load_path}\")\n",
    "        if use_mlflow:\n",
    "            mlflow.log_param(\"loaded_checkpoint\", load_path)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    # Only optimize trainable parameters\n",
    "    optimizer = optim.Adam(model.get_trainable_params(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
    "    \n",
    "    # Use device-specific GradScaler to avoid warnings\n",
    "    if device.type == 'cuda' and amp:\n",
    "        grad_scaler = torch.amp.GradScaler('cuda', enabled=True)\n",
    "    elif device.type == 'cpu' and amp:\n",
    "        # For CPU, disable AMP as it's not supported\n",
    "        print(\"Warning: AMP is not supported on CPU, disabling AMP\")\n",
    "        grad_scaler = torch.amp.GradScaler('cpu', enabled=False)\n",
    "        amp = False\n",
    "    else:\n",
    "        grad_scaler = torch.amp.GradScaler(device.type, enabled=amp)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        if optimizer.param_groups[0].get(\"lr\", 0) == 0:\n",
    "            print(\"Learning rate reached 0, stopping training\")\n",
    "            break\n",
    "        \n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "            images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "            labels = labels.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            # Use device-appropriate autocast\n",
    "            if amp and device.type == 'cuda':\n",
    "                with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            elif amp and device.type == 'cpu':\n",
    "                # CPU doesn't support autocast with float16, use bfloat16 if available\n",
    "                with torch.autocast(device_type='cpu', dtype=torch.bfloat16, enabled=torch.cpu.amp.is_autocast_available()):\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            else:\n",
    "                # No autocast\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if amp:\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.get_trainable_params(), 1.0)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.get_trainable_params(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100 * correct_predictions / total_predictions:.2f}%'\n",
    "            })\n",
    "        \n",
    "        mean_loss = epoch_loss / len(train_loader)\n",
    "        train_accuracy = correct_predictions / total_predictions\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Loss={mean_loss:.4f}, \"\n",
    "              f\"Train Acc={train_accuracy:.4f}, LR={optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        auc, sensitivity, specificity, test_accuracy, f1, ppv, confusion_mat, test_loss = test_model(\n",
    "            model, test_loader, epoch, \"test\", criterion, device)\n",
    "        \n",
    "        print(f\"Test Results - Accuracy: {test_accuracy:.4f}, F1: {f1:.4f}, \"\n",
    "              f\"Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n",
    "        \n",
    "        scheduler.step(test_accuracy)\n",
    "        \n",
    "        # Log metrics to MLflow\n",
    "        if use_mlflow:\n",
    "            mlflow.log_metric(\"train_loss\", mean_loss, step=epoch)\n",
    "            mlflow.log_metric(\"train_accuracy\", train_accuracy, step=epoch)\n",
    "            mlflow.log_metric(\"test_loss\", test_loss, step=epoch)\n",
    "            mlflow.log_metric(\"test_accuracy\", test_accuracy, step=epoch)\n",
    "            mlflow.log_metric(\"test_f1\", f1, step=epoch)\n",
    "            mlflow.log_metric(\"test_sensitivity\", sensitivity, step=epoch)\n",
    "            mlflow.log_metric(\"test_specificity\", specificity, step=epoch)\n",
    "            mlflow.log_metric(\"learning_rate\", optimizer.param_groups[0][\"lr\"], step=epoch)\n",
    "            if auc is not None:\n",
    "                mlflow.log_metric(\"test_auc\", auc, step=epoch)\n",
    "            mlflow.log_metric(\"test_precision\", ppv, step=epoch)\n",
    "        \n",
    "        # Save best model\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            if save_checkpoint:\n",
    "                Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "                best_model_path = os.path.join(save_path, f\"best_resnet50_finetuned.pth\")\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f'Best model saved with accuracy: {best_accuracy:.4f}')\n",
    "                \n",
    "                # Log best model to MLflow\n",
    "                if use_mlflow:\n",
    "                    mlflow.log_artifact(best_model_path, \"models\")\n",
    "                    mlflow.log_metric(\"best_accuracy\", best_accuracy)\n",
    "        \n",
    "        # Save periodic checkpoints\n",
    "        if save_checkpoint and (epoch + 1) % save_interval == 0:\n",
    "            Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "            checkpoint_path = os.path.join(save_path,\n",
    "                                           f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "                                           f\"_epoch{epoch+1}_resnet50_finetuned.pth\")\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f'Checkpoint saved: {checkpoint_path}')\n",
    "            \n",
    "            if use_mlflow:\n",
    "                mlflow.log_artifact(checkpoint_path, \"checkpoints\")\n",
    "    \n",
    "    # Log final model and end MLflow run\n",
    "    if use_mlflow:\n",
    "        mlflow.pytorch.log_model(model, \"final_model\")\n",
    "        mlflow.end_run()\n",
    "    \n",
    "    return model, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecec8f88-ebba-4ec2-9f2a-731d10f84879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function demonstrating ResNet50 fine-tuning.\"\"\"\n",
    "    \n",
    "    # Get device and configure AMP accordingly\n",
    "    device = get_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Enable AMP only for CUDA devices\n",
    "    use_amp = device.type == 'cuda'\n",
    "    if use_amp:\n",
    "        print(\"Mixed precision training enabled (AMP)\")\n",
    "    else:\n",
    "        print(\"Mixed precision training disabled (not supported on this device)\")\n",
    "    \n",
    "    # Configuration for chest x-ray dataset with ResNet50 fine-tuning\n",
    "    config = {\n",
    "        \"root_path\": \"C:/Users/sriha/NEU/shlabs/HP_NVIDIA/CellData/chest_xray\",  # Updated path for chest x-ray data\n",
    "        \"freeze_features\": True,  # Only fine-tune the last layer\n",
    "        \"epochs\": 15,  # More epochs for full dataset training\n",
    "        \"batch_size\": 32,  # Larger batch size for full dataset\n",
    "        \"lr\": 1e-3,  # Higher learning rate for the new classifier layer\n",
    "        \"seed\": 42,\n",
    "        \"save_checkpoint\": True,\n",
    "        \"save_interval\": 5,  # Save every 5 epochs\n",
    "        \"save_path\": \"./checkpoints\",\n",
    "        \"use_mlflow\": True,  # Use MLflow for experiment tracking\n",
    "        \"experiment_name\": \"ResNet50_ChestXray_FineTuning_Full\",\n",
    "        \"amp\": use_amp,  # Use AMP only if CUDA is available\n",
    "        \"device\": device,  # Pass device explicitly\n",
    "        \"normalize_mean\": [0.485, 0.456, 0.406],  # ImageNet normalization\n",
    "        \"normalize_std\": [0.229, 0.224, 0.225],   # ImageNet normalization\n",
    "        \"num_classes\": 2,  # Binary classification (NORMAL vs PNEUMONIA)\n",
    "        \"max_samples_per_class\": None,  # Use full dataset - no sample limit\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Starting ResNet50 fine-tuning on chest x-ray dataset...\")\n",
    "    print(\"Using ImageNet pretrained weights, fine-tuning only the last layer\")\n",
    "    print(\"Using full dataset for complete training\")\n",
    "    model, best_accuracy = train_resnet50_model(**config)\n",
    "    \n",
    "    print(f\"Training completed! Best accuracy: {best_accuracy:.4f}\")\n",
    "    print(f\"Model checkpoints saved in: {config['save_path']}\")\n",
    "    print(\"Check MLflow UI for detailed experiment tracking and metrics visualization.\")\n",
    "    print(\"Note: This was trained on the full dataset for complete training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "805d6335-c391-4ab7-9aa6-9b41733a0fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 16:58:36 INFO mlflow.tracking.fluent: Experiment with name 'ResNet50_ChestXray_FineTuning_Full' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow UI started in background\n",
      "Access the dashboard at: http://127.0.0.1:5000\n",
      "Process ID: 24448\n",
      "CUDA device detected: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Using device: cuda\n",
      "Mixed precision training enabled (AMP)\n",
      "Starting ResNet50 fine-tuning on chest x-ray dataset...\n",
      "Using ImageNet pretrained weights, fine-tuning only the last layer\n",
      "Using full dataset for complete training\n",
      "ResNet50 loaded with ImageNet weights. Final layer: 2048 -> 2\n",
      "All layers frozen except final classifier layer\n",
      "Total parameters: 23,512,130\n",
      "Trainable parameters: 4,098\n",
      "Percentage of trainable parameters: 0.02%\n",
      "Found 2 classes: ['NORMAL', 'PNEUMONIA']\n",
      "Total samples: 5232\n",
      "  NORMAL: 1349 samples\n",
      "  PNEUMONIA: 3883 samples\n",
      "Found 2 classes: ['NORMAL', 'PNEUMONIA']\n",
      "Total samples: 624\n",
      "  NORMAL: 234 samples\n",
      "  PNEUMONIA: 390 samples\n",
      "\n",
      "        Model: ResNet50 Fine-tuned (ImageNet pretrained)\n",
      "        Freeze features: True\n",
      "        Seed: 42, Batch size: 32, Epochs: 15\n",
      "        Learning rate: 0.001, Data path: C:/Users/sriha/NEU/shlabs/HP_NVIDIA/CellData/chest_xray\n",
      "        Training size: 5232, Test size: 624\n",
      "        Device: cuda, Save checkpoints: True\n",
      "        Trainable params: 4,098 / 23,512,130 (0.0%)\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|███████████████████████████████████████████| 164/164 [02:56<00:00,  1.08s/it, Loss=0.1661, Acc=89.09%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.2765, Train Acc=0.8909, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:18<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8494, F1: 0.8431, Sensitivity: 0.9615, Specificity: 0.6624\n",
      "Best model saved with accuracy: 0.8494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|███████████████████████████████████████████| 164/164 [02:56<00:00,  1.08s/it, Loss=0.1416, Acc=93.20%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=0.1839, Train Acc=0.9320, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:11<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8798, F1: 0.8765, Sensitivity: 0.9641, Specificity: 0.7393\n",
      "Best model saved with accuracy: 0.8798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|███████████████████████████████████████████| 164/164 [02:19<00:00,  1.17it/s, Loss=0.0761, Acc=94.07%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=0.1581, Train Acc=0.9407, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:12<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8686, F1: 0.8636, Sensitivity: 0.9718, Specificity: 0.6966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|███████████████████████████████████████████| 164/164 [02:24<00:00,  1.14it/s, Loss=0.2047, Acc=94.34%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.1442, Train Acc=0.9434, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:13<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8622, F1: 0.8565, Sensitivity: 0.9718, Specificity: 0.6795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|███████████████████████████████████████████| 164/164 [02:27<00:00,  1.11it/s, Loss=0.0630, Acc=94.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.1395, Train Acc=0.9471, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:13<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8958, F1: 0.8936, Sensitivity: 0.9667, Specificity: 0.7778\n",
      "Best model saved with accuracy: 0.8958\n",
      "Checkpoint saved: ./checkpoints\\20250531-171250_epoch5_resnet50_finetuned.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|███████████████████████████████████████████| 164/164 [02:28<00:00,  1.10it/s, Loss=0.0568, Acc=94.67%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.1374, Train Acc=0.9467, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:12<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.9006, F1: 0.8986, Sensitivity: 0.9692, Specificity: 0.7863\n",
      "Best model saved with accuracy: 0.9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|███████████████████████████████████████████| 164/164 [02:29<00:00,  1.09it/s, Loss=0.0634, Acc=95.05%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.1309, Train Acc=0.9505, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:13<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8926, F1: 0.8898, Sensitivity: 0.9718, Specificity: 0.7607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|███████████████████████████████████████████| 164/164 [02:30<00:00,  1.09it/s, Loss=0.6704, Acc=95.18%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.1327, Train Acc=0.9518, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:14<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.9087, F1: 0.9075, Sensitivity: 0.9590, Specificity: 0.8248\n",
      "Best model saved with accuracy: 0.9087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|███████████████████████████████████████████| 164/164 [02:28<00:00,  1.11it/s, Loss=0.1381, Acc=94.90%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.1271, Train Acc=0.9490, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:13<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8766, F1: 0.8720, Sensitivity: 0.9769, Specificity: 0.7094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████████████████████████████████████| 164/164 [02:29<00:00,  1.10it/s, Loss=0.4120, Acc=94.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.1262, Train Acc=0.9497, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:13<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8894, F1: 0.8861, Sensitivity: 0.9769, Specificity: 0.7436\n",
      "Checkpoint saved: ./checkpoints\\20250531-172625_epoch10_resnet50_finetuned.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████████████████████████████████████| 164/164 [02:30<00:00,  1.09it/s, Loss=0.1082, Acc=95.36%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.1239, Train Acc=0.9536, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:13<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8718, F1: 0.8663, Sensitivity: 0.9821, Specificity: 0.6880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████████████████████████████████████| 164/164 [02:27<00:00,  1.11it/s, Loss=0.0403, Acc=95.57%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.1186, Train Acc=0.9557, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:13<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8718, F1: 0.8665, Sensitivity: 0.9795, Specificity: 0.6923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|██████████████████████████████████████████| 164/164 [02:30<00:00,  1.09it/s, Loss=0.2188, Acc=95.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.1113, Train Acc=0.9576, LR=0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:12<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8846, F1: 0.8806, Sensitivity: 0.9795, Specificity: 0.7265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|██████████████████████████████████████████| 164/164 [02:28<00:00,  1.10it/s, Loss=0.2756, Acc=95.78%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.1098, Train Acc=0.9578, LR=0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:13<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.9054, F1: 0.9034, Sensitivity: 0.9744, Specificity: 0.7906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|██████████████████████████████████████████| 164/164 [02:28<00:00,  1.11it/s, Loss=0.0166, Acc=95.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.1128, Train Acc=0.9591, LR=0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:13<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8926, F1: 0.8895, Sensitivity: 0.9769, Specificity: 0.7521\n",
      "Checkpoint saved: ./checkpoints\\20250531-173956_epoch15_resnet50_finetuned.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 17:39:56 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/31 17:40:07 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.20.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torchvision==0.20.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/31 17:40:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed! Best accuracy: 0.9087\n",
      "Model checkpoints saved in: ./checkpoints\n",
      "Check MLflow UI for detailed experiment tracking and metrics visualization.\n",
      "Note: This was trained on the full dataset for complete training.\n"
     ]
    }
   ],
   "source": [
    "    import subprocess\n",
    "    import time\n",
    "\n",
    "    # Start MLflow UI in the background\n",
    "    mlflow.end_run()\n",
    "    mlflow_process = subprocess.Popen([\n",
    "        'mlflow', 'ui', \n",
    "        '--host', '127.0.0.1', \n",
    "        '--port', '5000'\n",
    "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    print(\"MLflow UI started in background\")\n",
    "    print(\"Access the dashboard at: http://127.0.0.1:5000\")\n",
    "    print(f\"Process ID: {mlflow_process.pid}\")\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c86f9-d9a3-4e48-99c3-4e520e03a26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python venv2",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
