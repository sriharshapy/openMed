{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14fa5ea4-7cd0-4208-b776-bbd3de7d8c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (0.19.1+cu124)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.12/site-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (70.0.0)\n",
      "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m767.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m00:03\u001b[0m\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp312-cp312-linux_x86_64.whl (798.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m00:03\u001b[0m\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.12/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.99\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.1+cu124\n",
      "    Uninstalling torch-2.4.1+cu124:\n",
      "      Successfully uninstalled torch-2.4.1+cu124\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eabf45a-761e-499e-948f-e257203f4303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 7)) (10.3.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 8)) (1.5.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 9)) (4.66.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 10)) (2.2.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 11)) (1.12.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 12)) (4.11.0.86)\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 13)) (1.0.15)\n",
      "Requirement already satisfied: shap in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 14)) (0.47.2)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 15)) (0.13.0)\n",
      "Requirement already satisfied: mlflow in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 16)) (2.18.0)\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 17)) (1.1.1)\n",
      "Requirement already satisfied: jupyterlab in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 18)) (4.3.4)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.12/site-packages (from -r ../../requirements.txt (line 21)) (0.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->-r ../../requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->-r ../../requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->-r ../../requirements.txt (line 10)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->-r ../../requirements.txt (line 10)) (2024.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (from timm->-r ../../requirements.txt (line 13)) (2.4.1+cu121)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (from timm->-r ../../requirements.txt (line 13)) (0.19.1+cu124)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from timm->-r ../../requirements.txt (line 13)) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.12/site-packages (from timm->-r ../../requirements.txt (line 13)) (0.32.4)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.12/site-packages (from timm->-r ../../requirements.txt (line 13)) (0.5.3)\n",
      "Requirement already satisfied: slicer==0.0.8 in /opt/conda/lib/python3.12/site-packages (from shap->-r ../../requirements.txt (line 14)) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in /opt/conda/lib/python3.12/site-packages (from shap->-r ../../requirements.txt (line 14)) (0.59.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.12/site-packages (from shap->-r ../../requirements.txt (line 14)) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.12/site-packages (from shap->-r ../../requirements.txt (line 14)) (4.12.2)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /opt/conda/lib/python3.12/site-packages (from imbalanced-learn->-r ../../requirements.txt (line 15)) (0.1.3)\n",
      "Requirement already satisfied: mlflow-skinny==2.18.0 in /opt/conda/lib/python3.12/site-packages (from mlflow->-r ../../requirements.txt (line 16)) (2.18.0)\n",
      "Requirement already satisfied: Flask<4 in /opt/conda/lib/python3.12/site-packages (from mlflow->-r ../../requirements.txt (line 16)) (3.1.0)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.12/site-packages (from mlflow->-r ../../requirements.txt (line 16)) (1.14.0)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.12/site-packages (from mlflow->-r ../../requirements.txt (line 16)) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /opt/conda/lib/python3.12/site-packages (from mlflow->-r ../../requirements.txt (line 16)) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.12/site-packages (from mlflow->-r ../../requirements.txt (line 16)) (3.7)\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in /opt/conda/lib/python3.12/site-packages (from mlflow->-r ../../requirements.txt (line 16)) (18.1.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from mlflow->-r ../../requirements.txt (line 16)) (2.0.37)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.12/site-packages (from mlflow->-r ../../requirements.txt (line 16)) (3.1.5)\n",
      "Requirement already satisfied: gunicorn<24 in /opt/conda/lib/python3.12/site-packages (from mlflow->-r ../../requirements.txt (line 16)) (22.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (8.1.8)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (0.40.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (3.1.44)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (1.29.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (0.5.3)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.12/site-packages (from jupyter->-r ../../requirements.txt (line 17)) (7.3.2)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.12/site-packages (from jupyter->-r ../../requirements.txt (line 17)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.12/site-packages (from jupyter->-r ../../requirements.txt (line 17)) (7.16.5)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.12/site-packages (from jupyter->-r ../../requirements.txt (line 17)) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.12/site-packages (from jupyter->-r ../../requirements.txt (line 17)) (8.0.7)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from jupyterlab->-r ../../requirements.txt (line 18)) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /opt/conda/lib/python3.12/site-packages (from jupyterlab->-r ../../requirements.txt (line 18)) (0.28.1)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.12/site-packages (from jupyterlab->-r ../../requirements.txt (line 18)) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from jupyterlab->-r ../../requirements.txt (line 18)) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from jupyterlab->-r ../../requirements.txt (line 18)) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/conda/lib/python3.12/site-packages (from jupyterlab->-r ../../requirements.txt (line 18)) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/conda/lib/python3.12/site-packages (from jupyterlab->-r ../../requirements.txt (line 18)) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.12/site-packages (from jupyterlab->-r ../../requirements.txt (line 18)) (70.0.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/conda/lib/python3.12/site-packages (from jupyterlab->-r ../../requirements.txt (line 18)) (6.4.2)\n",
      "Requirement already satisfied: traitlets in /opt/conda/lib/python3.12/site-packages (from jupyterlab->-r ../../requirements.txt (line 18)) (5.14.3)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow->-r ../../requirements.txt (line 16)) (1.3.8)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow->-r ../../requirements.txt (line 16)) (2.2.3)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /opt/conda/lib/python3.12/site-packages (from Flask<4->mlflow->-r ../../requirements.txt (line 16)) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /opt/conda/lib/python3.12/site-packages (from Flask<4->mlflow->-r ../../requirements.txt (line 16)) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /opt/conda/lib/python3.12/site-packages (from Flask<4->mlflow->-r ../../requirements.txt (line 16)) (1.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.12/site-packages (from graphene<4->mlflow->-r ../../requirements.txt (line 16)) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.12/site-packages (from graphene<4->mlflow->-r ../../requirements.txt (line 16)) (3.2.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab->-r ../../requirements.txt (line 18)) (4.8.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab->-r ../../requirements.txt (line 18)) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab->-r ../../requirements.txt (line 18)) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab->-r ../../requirements.txt (line 18)) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->-r ../../requirements.txt (line 18)) (0.14.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from ipykernel->jupyter->-r ../../requirements.txt (line 17)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.12/site-packages (from ipykernel->jupyter->-r ../../requirements.txt (line 17)) (1.8.11)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.12/site-packages (from ipykernel->jupyter->-r ../../requirements.txt (line 17)) (8.31.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.12/site-packages (from ipykernel->jupyter->-r ../../requirements.txt (line 17)) (8.6.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.12/site-packages (from ipykernel->jupyter->-r ../../requirements.txt (line 17)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.12/site-packages (from ipykernel->jupyter->-r ../../requirements.txt (line 17)) (1.6.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from ipykernel->jupyter->-r ../../requirements.txt (line 17)) (6.1.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.12/site-packages (from ipykernel->jupyter->-r ../../requirements.txt (line 17)) (26.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from Jinja2<4,>=2.11->mlflow->-r ../../requirements.txt (line 16)) (3.0.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.12/site-packages (from jupyter-core->jupyterlab->-r ../../requirements.txt (line 18)) (4.3.6)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/conda/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /opt/conda/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (0.11.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/conda/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /opt/conda/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/conda/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (0.21.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/conda/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/conda/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r ../../requirements.txt (line 18)) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r ../../requirements.txt (line 18)) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/conda/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r ../../requirements.txt (line 18)) (4.23.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.12/site-packages (from nbconvert->jupyter->-r ../../requirements.txt (line 17)) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r ../../requirements.txt (line 17)) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.12/site-packages (from nbconvert->jupyter->-r ../../requirements.txt (line 17)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.12/site-packages (from nbconvert->jupyter->-r ../../requirements.txt (line 17)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.12/site-packages (from nbconvert->jupyter->-r ../../requirements.txt (line 17)) (3.1.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.12/site-packages (from nbconvert->jupyter->-r ../../requirements.txt (line 17)) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.12/site-packages (from nbconvert->jupyter->-r ../../requirements.txt (line 17)) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /opt/conda/lib/python3.12/site-packages (from nbconvert->jupyter->-r ../../requirements.txt (line 17)) (2.19.1)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.12/site-packages (from numba>=0.54->shap->-r ../../requirements.txt (line 14)) (0.42.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy<3,>=1.4.0->mlflow->-r ../../requirements.txt (line 16)) (3.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from huggingface_hub->timm->-r ../../requirements.txt (line 13)) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub->timm->-r ../../requirements.txt (line 13)) (2024.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub->timm->-r ../../requirements.txt (line 13)) (1.1.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.12/site-packages (from ipywidgets->jupyter->-r ../../requirements.txt (line 17)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.12/site-packages (from ipywidgets->jupyter->-r ../../requirements.txt (line 17)) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/lib/python3.12/site-packages (from jupyter-console->jupyter->-r ../../requirements.txt (line 17)) (3.0.48)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.12/site-packages (from torch->timm->-r ../../requirements.txt (line 13)) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm->-r ../../requirements.txt (line 13)) (12.5.82)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->httpx>=0.25.0->jupyterlab->-r ../../requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->-r ../../requirements.txt (line 17)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r ../../requirements.txt (line 17)) (1.4.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/conda/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (2.37.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (3.21.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ../../requirements.txt (line 17)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ../../requirements.txt (line 17)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ../../requirements.txt (line 17)) (4.9.0)\n",
      "Requirement already satisfied: stack_data in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ../../requirements.txt (line 17)) (0.6.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->-r ../../requirements.txt (line 18)) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->-r ../../requirements.txt (line 18)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->-r ../../requirements.txt (line 18)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->-r ../../requirements.txt (line 18)) (0.22.3)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (0.1.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (2.21.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (1.2.15)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (0.50b0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.12/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r ../../requirements.txt (line 17)) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (3.4.0)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.12/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (0.7.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.12/site-packages (from beautifulsoup4->nbconvert->jupyter->-r ../../requirements.txt (line 17)) (2.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy->torch->timm->-r ../../requirements.txt (line 13)) (1.3.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (1.17.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (4.9)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r ../../requirements.txt (line 17)) (0.8.4)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/conda/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (1.17.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->-r ../../requirements.txt (line 17)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->-r ../../requirements.txt (line 17)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->-r ../../requirements.txt (line 17)) (0.2.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (2.22)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow->-r ../../requirements.txt (line 16)) (0.6.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../requirements.txt (line 18)) (2.9.0.20241206)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313c86f9-d9a3-4e48-99c3-4e520e03a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.backends import mps\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import mlflow.sklearn\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, confusion_matrix\n",
    "from imblearn.metrics import sensitivity_score, specificity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76919694-9a99-4213-848d-fc661b37de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Get the best available device for training.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"CUDA device detected: {torch.cuda.get_device_name()}\")\n",
    "        return device\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"MPS device detected (Apple Silicon)\")\n",
    "        return device\n",
    "    else:\n",
    "        print(\"No GPU available, using CPU\")\n",
    "        return torch.device(\"cpu\")\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90826f5d-08ef-4624-a9eb-414897fcc2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device detected: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a7026e-e742-4cff-b9ba-b833f138f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50FineTuned(nn.Module):\n",
    "    \"\"\"ResNet50 with ImageNet pretrained weights, fine-tuning only the last layer.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2, freeze_features=True):\n",
    "        super(ResNet50FineTuned, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet50\n",
    "        self.resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        \n",
    "        # Freeze all layers except the final classifier if freeze_features=True\n",
    "        if freeze_features:\n",
    "            for param in self.resnet50.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        # ResNet50 has 2048 features in the final layer\n",
    "        num_features = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        # Ensure the final layer is trainable\n",
    "        for param in self.resnet50.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        print(f\"ResNet50 loaded with ImageNet weights. Final layer: {num_features} -> {num_classes}\")\n",
    "        if freeze_features:\n",
    "            print(\"All layers frozen except final classifier layer\")\n",
    "        else:\n",
    "            print(\"All layers trainable\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "    \n",
    "    def get_trainable_params(self):\n",
    "        \"\"\"Return only trainable parameters.\"\"\"\n",
    "        return [param for param in self.parameters() if param.requires_grad]\n",
    "    \n",
    "    def get_num_trainable_params(self):\n",
    "        \"\"\"Return number of trainable parameters.\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e590e7b6-2d07-4136-9024-f28e81d24864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnResNet50Wrapper(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Scikit-learn compatible wrapper for PyTorch ResNet50 model.\"\"\"\n",
    "    \n",
    "    def __init__(self, pytorch_model, device, transform=None):\n",
    "        self.pytorch_model = pytorch_model\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "        self.classes_ = np.array([0, 1])  # Binary classification\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Dummy fit method for scikit-learn compatibility.\"\"\"\n",
    "        # The actual training is done outside this wrapper\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels for samples in X.\"\"\"\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return np.argmax(probabilities, axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities for samples in X.\"\"\"\n",
    "        self.pytorch_model.eval()\n",
    "        all_probabilities = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x in X:\n",
    "                if self.transform and not isinstance(x, torch.Tensor):\n",
    "                    if isinstance(x, np.ndarray):\n",
    "                        # Convert numpy array to PIL Image for transforms\n",
    "                        x = Image.fromarray((x * 255).astype(np.uint8))\n",
    "                    x = self.transform(x)\n",
    "                \n",
    "                if not isinstance(x, torch.Tensor):\n",
    "                    x = torch.tensor(x, dtype=torch.float32)\n",
    "                \n",
    "                x = x.unsqueeze(0).to(self.device)  # Add batch dimension\n",
    "                outputs = self.pytorch_model(x)\n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                all_probabilities.append(probabilities.cpu().numpy()[0])\n",
    "        \n",
    "        return np.array(all_probabilities)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Return the mean accuracy on the given test data and labels.\"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return accuracy_score(y, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "410864f0-620d-4734-a0d6-cb98baf88775",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"Custom dataset for chest x-ray classification.\"\"\"\n",
    "    def __init__(self, root_dir, transform=None, max_samples_per_class=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with subdirectories for each class (NORMAL, PNEUMONIA)\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            max_samples_per_class (int, optional): Maximum number of samples per class to load.\n",
    "                                                  If None, loads all samples.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "        self.max_samples_per_class = max_samples_per_class\n",
    "        \n",
    "        # Get class directories\n",
    "        class_dirs = [d for d in os.listdir(root_dir) \n",
    "                     if os.path.isdir(os.path.join(root_dir, d))]\n",
    "        class_dirs.sort()  # Ensure consistent ordering\n",
    "        self.class_names = class_dirs\n",
    "        \n",
    "        print(f\"Found {len(class_dirs)} classes: {class_dirs}\")\n",
    "        if max_samples_per_class:\n",
    "            print(f\"Limiting to {max_samples_per_class} samples per class\")\n",
    "        \n",
    "        # Create mapping from class name to index\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(class_dirs)}\n",
    "        \n",
    "        # Collect all image paths and labels\n",
    "        for class_name in class_dirs:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            # Get all image files for this class\n",
    "            class_images = []\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    class_images.append(os.path.join(class_dir, img_name))\n",
    "            \n",
    "            # Limit samples per class if specified\n",
    "            if max_samples_per_class and len(class_images) > max_samples_per_class:\n",
    "                # Randomly sample max_samples_per_class images\n",
    "                import random\n",
    "                random.seed(42)  # For reproducibility\n",
    "                class_images = random.sample(class_images, max_samples_per_class)\n",
    "            \n",
    "            # Add to dataset\n",
    "            for img_path in class_images:\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(class_idx)\n",
    "        \n",
    "        print(f\"Total samples: {len(self.image_paths)}\")\n",
    "        for class_name, class_idx in self.class_to_idx.items():\n",
    "            count = sum(1 for label in self.labels if label == class_idx)\n",
    "            print(f\"  {class_name}: {count} samples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2fe9735-6314-481b-a5b9-f742bc7117bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, epoch: int = -1, dataset: str = \"\", criterion=None, device=None):\n",
    "    \"\"\"Evaluate model performance on test set.\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=f\"Testing {dataset}\"):\n",
    "            images = images.to(device=device, dtype=torch.float32)\n",
    "            labels = labels.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            if criterion:\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "            \n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probabilities = np.array(all_probabilities)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    # For binary classification, calculate additional metrics\n",
    "    if all_probabilities.shape[1] == 2:\n",
    "        try:\n",
    "            auc = roc_auc_score(all_labels, all_probabilities[:, 1])\n",
    "        except ValueError:\n",
    "            auc = None\n",
    "            \n",
    "        sensitivity = sensitivity_score(all_labels, all_predictions, average='binary')\n",
    "        specificity = specificity_score(all_labels, all_predictions, average='binary')\n",
    "        ppv = precision_score(all_labels, all_predictions, average='binary')\n",
    "    else:\n",
    "        auc = None\n",
    "        sensitivity = sensitivity_score(all_labels, all_predictions, average='macro')\n",
    "        specificity = specificity_score(all_labels, all_predictions, average='macro')\n",
    "        ppv = precision_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    confusion_mat = confusion_matrix(all_labels, all_predictions)\n",
    "    test_loss = test_loss / len(test_loader) if criterion else 0\n",
    "    \n",
    "    return auc, sensitivity, specificity, accuracy, f1, ppv, confusion_mat, test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2847dec-c322-42f3-8c30-b6ee32a0e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet50_model(\n",
    "        root_path: str,\n",
    "        freeze_features: bool = True,\n",
    "        normalize_mean: list = [0.485, 0.456, 0.406],\n",
    "        normalize_std: list = [0.229, 0.224, 0.225],\n",
    "        epochs: int = 10,\n",
    "        batch_size: int = 32,\n",
    "        lr: float = 1e-3,\n",
    "        seed: int = 42,\n",
    "        load_path: str = \"\",\n",
    "        save_checkpoint: bool = True,\n",
    "        save_interval: int = 5,\n",
    "        save_path: str = \"./checkpoints/resnet50\",\n",
    "        use_mlflow: bool = True,\n",
    "        experiment_name: str = \"ResNet50_ChestXray_FineTuning\",\n",
    "        device=None,\n",
    "        amp: bool = False,\n",
    "        num_classes: int = 2,\n",
    "        max_samples_per_class: int = None\n",
    "):\n",
    "    \"\"\"Main training function for ResNet50 fine-tuning.\"\"\"\n",
    "    \n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Start MLflow run\n",
    "    if use_mlflow:\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        mlflow.start_run()\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model_type\", \"ResNet50_FineTuned\")\n",
    "        mlflow.log_param(\"freeze_features\", freeze_features)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"seed\", seed)\n",
    "        mlflow.log_param(\"device\", device.type)\n",
    "        mlflow.log_param(\"amp\", amp)\n",
    "        mlflow.log_param(\"num_classes\", num_classes)\n",
    "        mlflow.log_param(\"normalize_mean\", normalize_mean)\n",
    "        mlflow.log_param(\"normalize_std\", normalize_std)\n",
    "        mlflow.log_param(\"max_samples_per_class\", max_samples_per_class)\n",
    "    \n",
    "    # Create model\n",
    "    model = ResNet50FineTuned(num_classes=num_classes, freeze_features=freeze_features)\n",
    "    \n",
    "    # Log model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = model.get_num_trainable_params()\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Percentage of trainable parameters: {100 * trainable_params / total_params:.2f}%\")\n",
    "    \n",
    "    if use_mlflow:\n",
    "        mlflow.log_param(\"total_params\", total_params)\n",
    "        mlflow.log_param(\"trainable_params\", trainable_params)\n",
    "        mlflow.log_param(\"trainable_percentage\", 100 * trainable_params / total_params)\n",
    "    \n",
    "    # Create datasets with ImageNet normalization\n",
    "    normalize = transforms.Normalize(normalize_mean, normalize_std)\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomAffine(degrees=10, translate=(0.02, 0.02)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    \n",
    "    # Use chest x-ray dataset structure\n",
    "    train_dir = os.path.join(root_path, \"train\")\n",
    "    test_dir = os.path.join(root_path, \"test\")\n",
    "    \n",
    "    if not all(os.path.exists(path) for path in [train_dir, test_dir]):\n",
    "        raise FileNotFoundError(f\"Required data directories not found in {root_path}. \"\n",
    "                                f\"Ensure train/ and test/ directories exist.\")\n",
    "    \n",
    "    dataset_train = ChestXrayDataset(root_dir=train_dir, transform=train_transform, max_samples_per_class=max_samples_per_class)\n",
    "    dataset_test = ChestXrayDataset(root_dir=test_dir, transform=test_transform, max_samples_per_class=max_samples_per_class)\n",
    "    \n",
    "    train_loader = DataLoader(dataset_train, batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(dataset_test, batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Log dataset information\n",
    "    if use_mlflow:\n",
    "        mlflow.log_param(\"train_size\", len(dataset_train))\n",
    "        mlflow.log_param(\"test_size\", len(dataset_test))\n",
    "        mlflow.log_param(\"data_path\", root_path)\n",
    "    \n",
    "    # Training setup\n",
    "    info = f'''\n",
    "        Model: ResNet50 Fine-tuned (ImageNet pretrained)\n",
    "        Freeze features: {freeze_features}\n",
    "        Seed: {seed}, Batch size: {batch_size}, Epochs: {epochs}\n",
    "        Learning rate: {lr}, Data path: {root_path}\n",
    "        Training size: {len(dataset_train)}, Test size: {len(dataset_test)}\n",
    "        Device: {device.type}, Save checkpoints: {save_checkpoint}\n",
    "        Trainable params: {trainable_params:,} / {total_params:,} ({100 * trainable_params / total_params:.1f}%)\n",
    "    '''\n",
    "    print(info)\n",
    "    \n",
    "    if load_path and os.path.exists(load_path):\n",
    "        model.load_state_dict(torch.load(load_path, map_location=device))\n",
    "        print(f\"Loaded checkpoint from {load_path}\")\n",
    "        if use_mlflow:\n",
    "            mlflow.log_param(\"loaded_checkpoint\", load_path)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    # Only optimize trainable parameters\n",
    "    optimizer = optim.Adam(model.get_trainable_params(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
    "    \n",
    "    # Use device-specific GradScaler to avoid warnings\n",
    "    if device.type == 'cuda' and amp:\n",
    "        grad_scaler = torch.amp.GradScaler('cuda', enabled=True)\n",
    "    elif device.type == 'cpu' and amp:\n",
    "        # For CPU, disable AMP as it's not supported\n",
    "        print(\"Warning: AMP is not supported on CPU, disabling AMP\")\n",
    "        grad_scaler = torch.amp.GradScaler('cpu', enabled=False)\n",
    "        amp = False\n",
    "    else:\n",
    "        grad_scaler = torch.amp.GradScaler(device.type, enabled=amp)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        if optimizer.param_groups[0].get(\"lr\", 0) == 0:\n",
    "            print(\"Learning rate reached 0, stopping training\")\n",
    "            break\n",
    "        \n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "            images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "            labels = labels.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            # Use device-appropriate autocast\n",
    "            if amp and device.type == 'cuda':\n",
    "                with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            elif amp and device.type == 'cpu':\n",
    "                # CPU doesn't support autocast with float16, use bfloat16 if available\n",
    "                with torch.autocast(device_type='cpu', dtype=torch.bfloat16, enabled=torch.cpu.amp.is_autocast_available()):\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            else:\n",
    "                # No autocast\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if amp:\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.get_trainable_params(), 1.0)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.get_trainable_params(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100 * correct_predictions / total_predictions:.2f}%'\n",
    "            })\n",
    "        \n",
    "        mean_loss = epoch_loss / len(train_loader)\n",
    "        train_accuracy = correct_predictions / total_predictions\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Loss={mean_loss:.4f}, \"\n",
    "              f\"Train Acc={train_accuracy:.4f}, LR={optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        auc, sensitivity, specificity, test_accuracy, f1, ppv, confusion_mat, test_loss = test_model(\n",
    "            model, test_loader, epoch, \"test\", criterion, device)\n",
    "        \n",
    "        print(f\"Test Results - Accuracy: {test_accuracy:.4f}, F1: {f1:.4f}, \"\n",
    "              f\"Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n",
    "        \n",
    "        scheduler.step(test_accuracy)\n",
    "        \n",
    "        # Log metrics to MLflow\n",
    "        if use_mlflow:\n",
    "            mlflow.log_metric(\"train_loss\", mean_loss, step=epoch)\n",
    "            mlflow.log_metric(\"train_accuracy\", train_accuracy, step=epoch)\n",
    "            mlflow.log_metric(\"test_loss\", test_loss, step=epoch)\n",
    "            mlflow.log_metric(\"test_accuracy\", test_accuracy, step=epoch)\n",
    "            mlflow.log_metric(\"test_f1\", f1, step=epoch)\n",
    "            mlflow.log_metric(\"test_sensitivity\", sensitivity, step=epoch)\n",
    "            mlflow.log_metric(\"test_specificity\", specificity, step=epoch)\n",
    "            mlflow.log_metric(\"learning_rate\", optimizer.param_groups[0][\"lr\"], step=epoch)\n",
    "            if auc is not None:\n",
    "                mlflow.log_metric(\"test_auc\", auc, step=epoch)\n",
    "            mlflow.log_metric(\"test_precision\", ppv, step=epoch)\n",
    "        \n",
    "        # Save best model\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            if save_checkpoint:\n",
    "                Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "                best_model_path = os.path.join(save_path, f\"best_resnet50_finetuned.pth\")\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f'Best model saved with accuracy: {best_accuracy:.4f}')\n",
    "                \n",
    "                # Log best model to MLflow\n",
    "                if use_mlflow:\n",
    "                    mlflow.log_artifact(best_model_path, \"models\")\n",
    "                    mlflow.log_metric(\"best_accuracy\", best_accuracy)\n",
    "        \n",
    "        # Save periodic checkpoints\n",
    "        if save_checkpoint and (epoch + 1) % save_interval == 0:\n",
    "            Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "            checkpoint_path = os.path.join(save_path,\n",
    "                                           f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "                                           f\"_epoch{epoch+1}_resnet50_finetuned.pth\")\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f'Checkpoint saved: {checkpoint_path}')\n",
    "            \n",
    "            if use_mlflow:\n",
    "                mlflow.log_artifact(checkpoint_path, \"checkpoints\")\n",
    "    \n",
    "    # Log final model and end MLflow run\n",
    "    if use_mlflow:\n",
    "        # Create sklearn wrapper for the PyTorch model\n",
    "        sklearn_model = SklearnResNet50Wrapper(\n",
    "            pytorch_model=model,\n",
    "            device=device,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=normalize_mean, std=normalize_std)\n",
    "            ])\n",
    "        )\n",
    "        \n",
    "        # Get a sample from training data for input_example\n",
    "        # Convert a few training samples to the format expected by sklearn wrapper\n",
    "        sample_images = []\n",
    "        sample_count = 0\n",
    "        for images, _ in train_loader:\n",
    "            for img in images:\n",
    "                if sample_count >= 5:  # Get 5 sample images\n",
    "                    break\n",
    "                # Convert tensor back to numpy array (0-1 range)\n",
    "                img_np = img.permute(1, 2, 0).cpu().numpy()\n",
    "                # Ensure values are in 0-1 range\n",
    "                img_np = np.clip(img_np, 0, 1)\n",
    "                sample_images.append(img_np)\n",
    "                sample_count += 1\n",
    "            if sample_count >= 5:\n",
    "                break\n",
    "        \n",
    "        X_train_sample = np.array(sample_images)\n",
    "        \n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=sklearn_model,\n",
    "            artifact_path=\"sklearn-model\",\n",
    "            input_example=X_train_sample,\n",
    "            registered_model_name=\"resnet50-chest-xray-model\"\n",
    "        )\n",
    "        mlflow.end_run()\n",
    "    \n",
    "    return model, best_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e82434a9-8161-4b62-8a94-39b53a68e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function demonstrating ResNet50 fine-tuning.\"\"\"\n",
    "    \n",
    "    # Get device and configure AMP accordingly\n",
    "    device = get_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Enable AMP only for CUDA devices\n",
    "    use_amp = device.type == 'cuda'\n",
    "    if use_amp:\n",
    "        print(\"Mixed precision training enabled (AMP)\")\n",
    "    else:\n",
    "        print(\"Mixed precision training disabled (not supported on this device)\")\n",
    "    \n",
    "    # Configuration for chest x-ray dataset with ResNet50 fine-tuning\n",
    "    config = {\n",
    "        \"root_path\": \"../../../datafabric/PNEUMONIA/\",  # Updated path for chest x-ray data\n",
    "        \"freeze_features\": True,  # Only fine-tune the last layer\n",
    "        \"epochs\": 1,  # More epochs for full dataset training\n",
    "        \"batch_size\": 32,  # Larger batch size for full dataset\n",
    "        \"lr\": 1e-3,  # Higher learning rate for the new classifier layer\n",
    "        \"seed\": 42,\n",
    "        \"save_checkpoint\": True,\n",
    "        \"save_interval\": 5,  # Save every 5 epochs\n",
    "        \"save_path\": \"./checkpoints/resnet50\",\n",
    "        \"use_mlflow\": True,  # Use MLflow for experiment tracking\n",
    "        \"experiment_name\": \"ResNet50_ChestXray_FineTuning_Full\",\n",
    "        \"amp\": use_amp,  # Use AMP only if CUDA is available\n",
    "        \"device\": device,  # Pass device explicitly\n",
    "        \"normalize_mean\": [0.485, 0.456, 0.406],  # ImageNet normalization\n",
    "        \"normalize_std\": [0.229, 0.224, 0.225],   # ImageNet normalization\n",
    "        \"num_classes\": 2,  # Binary classification (NORMAL vs PNEUMONIA)\n",
    "        \"max_samples_per_class\": None,  # Use full dataset - no sample limit\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Starting ResNet50 fine-tuning on chest x-ray dataset...\")\n",
    "    print(\"Using ImageNet pretrained weights, fine-tuning only the last layer\")\n",
    "    print(\"Using full dataset for complete training\")\n",
    "    model, best_accuracy = train_resnet50_model(**config)\n",
    "    \n",
    "    print(f\"Training completed! Best accuracy: {best_accuracy:.4f}\")\n",
    "    print(f\"Model checkpoints saved in: {config['save_path']}\")\n",
    "    print(\"Check MLflow UI for detailed experiment tracking and metrics visualization.\")\n",
    "    print(\"Note: This was trained on the full dataset for complete training.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba5586f-5dbf-4786-892b-ea255289bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9386a944-2302-491b-b5d8-4d0605071986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device detected: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Using device: cuda\n",
      "Mixed precision training enabled (AMP)\n",
      "Starting ResNet50 fine-tuning on chest x-ray dataset...\n",
      "Using ImageNet pretrained weights, fine-tuning only the last layer\n",
      "Using full dataset for complete training\n",
      "ResNet50 loaded with ImageNet weights. Final layer: 2048 -> 2\n",
      "All layers frozen except final classifier layer\n",
      "Total parameters: 23,512,130\n",
      "Trainable parameters: 4,098\n",
      "Percentage of trainable parameters: 0.02%\n",
      "Found 2 classes: ['NORMAL', 'PNEUMONIA']\n",
      "Total samples: 5232\n",
      "  NORMAL: 1349 samples\n",
      "  PNEUMONIA: 3883 samples\n",
      "Found 2 classes: ['NORMAL', 'PNEUMONIA']\n",
      "Total samples: 624\n",
      "  NORMAL: 234 samples\n",
      "  PNEUMONIA: 390 samples\n",
      "\n",
      "        Model: ResNet50 Fine-tuned (ImageNet pretrained)\n",
      "        Freeze features: True\n",
      "        Seed: 42, Batch size: 32, Epochs: 1\n",
      "        Learning rate: 0.001, Data path: ../../../datafabric/PNEUMONIA/\n",
      "        Training size: 5232, Test size: 624\n",
      "        Device: cuda, Save checkpoints: True\n",
      "        Trainable params: 4,098 / 23,512,130 (0.0%)\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 164/164 [02:50<00:00,  1.04s/it, Loss=0.1663, Acc=89.09%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.2765, Train Acc=0.8909, LR=0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing test: 100%|██████████| 20/20 [00:19<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Accuracy: 0.8494, F1: 0.8431, Sensitivity: 0.9615, Specificity: 0.6624\n",
      "Best model saved with accuracy: 0.8494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/03 16:11:05 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.19.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torchvision==0.19.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Successfully registered model 'resnet50-chest-xray-model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed! Best accuracy: 0.8494\n",
      "Model checkpoints saved in: ./checkpoints/resnet50\n",
      "Check MLflow UI for detailed experiment tracking and metrics visualization.\n",
      "Note: This was trained on the full dataset for complete training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'resnet50-chest-xray-model'.\n"
     ]
    }
   ],
   "source": [
    "main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd127f-ef6f-400a-b5b7-b628d5437a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2e15f-74f6-49d0-9c22-e6ba774e349f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0f730-211a-4b91-8842-1925ef48dda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a996133-826b-42ca-ae62-5bc83a1e9765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc17c746-3faa-472b-a7de-d92fd28121f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e75a4-f923-4d67-bf1e-6ac408473152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f9cc1-1755-495b-8f65-60e292dd89b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9315c4b7-2e2b-4f99-bea2-bbd9f2bb99c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187efaa-0f89-4aa5-bd7c-0694342943ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4df43-1e7e-43dc-8a58-bd03ba111115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92acb9e2-9d9f-4a00-8825-60c5bef575ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030f2dc-34fd-404a-97bd-4b62d4a6ab78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71914e5e-c6fd-44b1-83db-265dd455ad58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd0e0f7-1333-448a-ad27-47c093b3f881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c0eab-63c3-4df6-bb6f-47f1e6327a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
